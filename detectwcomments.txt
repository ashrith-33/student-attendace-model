
import face_recognition
import cv2
import os
import pickle
import numpy as np
import time
import sys

# --- Configuration ---
# Path to the pickle file containing known face encodings and names
ENCODINGS_FILE = "trained_faces.pkl"

# Choose input source: 'image', 'video', or 'webcam'
# Set to 'image' for static image, 'video' for a video file, 'webcam' for live feed

# IMPORTANT: Only ONE of the INPUT_SOURCE lines below should be uncommented.
# This version is set up for webcam access by default.

# If you want webcam, uncomment this line:
#INPUT_SOURCE = 'webcam' # THIS IS UNCOMMENTED FOR WEBCAM ACCESS

# If you want image detection, uncomment this line and comment the 'webcam' line above:
INPUT_SOURCE = 'image'

# If you want video detection, uncomment this line and comment the others:
# VIDEO_PATH = "test_video.mp4" # Make sure this video file exists in the same directory
# INPUT_SOURCE = 'video'


# If INPUT_SOURCE is 'image', specify the path to the image
IMAGE_PATH = "test_image.jpg" # Make sure this image exists in the same directory

# If INPUT_SOURCE is 'video', specify the path to the video file
# VIDEO_PATH = "test_video.mp4" # Make sure this video file exists in the same directory

# Face detection and recognition parameters
# How many frames to skip before running face detection again (for performance).
# A value of 1 means process every frame. Higher values mean faster but less frequent detection.
# Experiment with 3, 4, or 5 for smoother results on less powerful machines.
# A higher value means less frequent detection, but smoother video.
FRAME_SKIP_INTERVAL = 1 # Adjusted for smoother webcam feed

# Tolerance for face comparison. Lower value means stricter match.
# Default for face_recognition.compare_faces is 0.6.
# Adjust this based on your dataset and desired accuracy.
# Lowering it might reduce false positives but increase false negatives.
RECOGNITION_TOLERANCE = 0.4

# --- TEMPORARY DEBUGGING START ---
# The debugging lines have been removed.
# --- TEMPORARY DEBUGGING END ---


def load_encodings(file_path):
    """
    Loads known face encodings and names from a pickle file.

    Args:
        file_path (str): The path to the pickle file.

    Returns:
        tuple: A tuple containing two lists:
               - known_face_encodings (list): List of face encodings.
               - known_face_names (list): List of corresponding names.
    """
    print(f"[INFO] Loading encodings from {file_path}...")
    if not os.path.exists(file_path):
        print(f"[ERROR] Encoded faces file '{file_path}' not found. "
              "Please run 'train.py' first to generate it.")
        return [], []
    try:
        with open(file_path, "rb") as f:
            data = pickle.load(f)
            return data["encodings"], data["names"]
    except Exception as e:
        print(f"[ERROR] Could not load encodings from {file_path}: {e}")
        return [], []

def process_frame(frame, known_face_encodings, known_face_names, frame_number, process_this_frame, current_fps):
    """
    Detects and recognizes faces in a single frame.

    Args:
        frame (numpy.ndarray): The current video frame or image.
        known_face_encodings (list): List of known face encodings.
        known_face_names (list): List of corresponding names.
        frame_number (int): The current frame number (for logging).
        process_this_frame (bool): True if face detection should run on this frame, False otherwise.
        current_fps (float): The current calculated frames per second.

    Returns:
        numpy.ndarray: The frame with annotated faces and FPS displayed.
    """
    # Initialize face_locations and face_names to be empty if not processed this frame
    # This prevents drawing old boxes if a face moves out of view and isn't re-detected.
    face_locations = []
    face_encodings = []
    face_names = []

    # Resize frame for faster processing, then convert to RGB
    # (face_recognition expects RGB, OpenCV reads BGR)
    # Reducing fx/fy further (e.g., 0.125 for 1/8th size) can increase speed but reduce accuracy,
    # especially for smaller or less clear faces. Experiment to find the balance.
    small_frame = cv2.resize(frame, (0, 0), fx=0.25, fy=0.25) # 1/4th size (1/16th pixels)
    rgb_small_frame = cv2.cvtColor(small_frame, cv2.COLOR_BGR2RGB)

    if process_this_frame:
        # Find all the faces and face encodings in the current frame
        face_locations = face_recognition.face_locations(rgb_small_frame)
        face_encodings = face_recognition.face_encodings(rgb_small_frame, face_locations)

        face_names = []
        for face_encoding in face_encodings:
            # Compare current face with known faces
            matches = face_recognition.compare_faces(known_face_encodings, face_encoding, tolerance=RECOGNITION_TOLERANCE)
            name = "Unknown"

            # Find the best match if any
            face_distances = face_recognition.face_distance(known_face_encodings, face_encoding)
            best_match_index = np.argmin(face_distances)

            if matches[best_match_index]:
                name = known_face_names[best_match_index]

            face_names.append(name)
    else:
        # If not processing this frame, we don't update face_locations/face_names.
        # For a truly smooth experience, especially when FRAME_SKIP_INTERVAL is high,
        # a face tracking algorithm (e.g., OpenCV's KCF, CSRT trackers) would be
        # implemented here to estimate the new positions of previously detected faces.
        # This would draw bounding boxes even on frames where full detection isn't run.
        pass


    # Draw bounding boxes and labels
    for (top, right, bottom, left), name in zip(face_locations, face_names):
        # Scale back up face locations since the frame was resized
        top *= 4
        right *= 4
        bottom *= 4
        left *= 4

        # Draw a box around the face
        cv2.rectangle(frame, (left, top), (right, bottom), (0, 255, 0), 2) # Green rectangle

        # Draw a label with a name below the face
        cv2.rectangle(frame, (left, bottom - 35), (right, bottom), (0, 255, 0), cv2.FILLED)
        font = cv2.FONT_HERSHEY_DUPLEX
        cv2.putText(frame, name, (left + 6, bottom - 6), font, 0.7, (255, 255, 255), 1) # White text

    # Display FPS on the frame
    cv2.putText(frame, f"FPS: {current_fps:.2f}", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)

    return frame

def run_detection():
    """
    Main function to run the person detection based on the configured input source.
    """
    known_face_encodings, known_face_names = load_encodings(ENCODINGS_FILE)

    if not known_face_encodings:
        print("[ERROR] Exiting: No known faces available for detection.")
        sys.exit(1)

    video_capture = None
    if INPUT_SOURCE == 'webcam':
        video_capture = cv2.VideoCapture(0) # 0 for default webcam
        if not video_capture.isOpened():
            print("[ERROR] Could not open webcam. Exiting.")
            print("Please check:")
            print("  1. If your webcam is connected and working.")
            print("  2. If other applications are using the webcam.")
            print("  3. Your system's privacy settings for camera access.")
            print("  4. Try changing cv2.VideoCapture(0) to (1), (2), etc., if you have multiple cameras.")
            sys.exit(1)
        print("[INFO] Starting webcam feed. Press 'q' to quit.")
        print("IMPORTANT: Click on the OpenCV window to make it active before pressing 'q' to quit.")
    elif INPUT_SOURCE == 'video':
        if not os.path.exists(VIDEO_PATH):
            print(f"[ERROR] Video file '{VIDEO_PATH}' not found. Exiting.")
            sys.exit(1)
        video_capture = cv2.VideoCapture(VIDEO_PATH)
        if not video_capture.isOpened():
            print(f"[ERROR] Could not open video file '{VIDEO_PATH}'. Exiting.")
            sys.exit(1)
        print(f"[INFO] Processing video: {VIDEO_PATH}. Press 'q' to quit.")
        print("IMPORTANT: Click on the OpenCV window to make it active before pressing 'q' to quit.")
    elif INPUT_SOURCE == 'image':
        # If INPUT_SOURCE is 'image', the script will reach here.
        # It will use IMAGE_PATH, which is currently "test_image.jpg".
        if not os.path.exists(IMAGE_PATH):
            print(f"[ERROR] Image file '{IMAGE_PATH}' not found. Exiting.")
            sys.exit(1)
        print(f"[INFO] Processing image: {IMAGE_PATH}.")
        image = cv2.imread(IMAGE_PATH)
        if image is None:
            print(f"[ERROR] Could not load image '{IMAGE_PATH}'. Exiting.")
            sys.exit(1)
        # For a single image, always process it fully
        processed_image = process_frame(image, known_face_encodings, known_face_names, 0, True, 0.0) # FPS not relevant for static image
        cv2.imshow('Person Detection Result', processed_image)
        cv2.waitKey(0) # Wait indefinitely until a key is pressed
        cv2.destroyAllWindows()
        return # This return statement exits the run_detection function
    else:
        print(f"[ERROR] Invalid INPUT_SOURCE: '{INPUT_SOURCE}'. Choose 'image', 'video', or 'webcam'.")
        sys.exit(1)

    # The loop below is only for 'webcam' or 'video' input.
    # If INPUT_SOURCE was 'image', the function would have returned already.
    # So, we only enter this loop if video_capture is expected to be valid.
    frame_count = 0
    start_time = time.time()
    fps = 0.0

    while True:
        ret, frame = video_capture.read()
        if not ret:
            print("[INFO] End of video stream or failed to read frame.")
            break

        frame_count += 1
        # Determine if we should run full face detection on this frame
        process_this_frame = (frame_count % FRAME_SKIP_INTERVAL == 0)

        # Process the frame, passing current FPS
        processed_frame = process_frame(frame, known_face_encodings, known_face_names, frame_count, process_this_frame, fps)

        # Display the resulting image
        cv2.imshow('Video/Webcam Feed - Person Detection', processed_frame)

        # Calculate FPS
        if frame_count % 10 == 0: # Update FPS every 10 frames for smoother display
            end_time = time.time()
            fps = 10 / (end_time - start_time)
            start_time = time.time()


        # Press 'q' on the keyboard to exit the feed
        # IMPORTANT: You MUST click on the OpenCV window to make it active
        # before pressing 'q' for it to register.
        key = cv2.waitKey(1) & 0xFF
        if key == ord('q'):
            print("[INFO] 'q' pressed. Exiting.")
            break

    # Release handle to the webcam or video file and close all OpenCV windows
    # This part is only reached if INPUT_SOURCE was 'webcam' or 'video'
    video_capture.release()
    cv2.destroyAllWindows()
    print("[INFO] Detection process finished.")

if __name__ == "__main__":
    run_detection()
